<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="icon" style="border-radius: 50px;" href="Assets/logo-modifie.png" type="image/png">
  <title>iVA | Intelligence Virtual Arena </title>
  <!--Google Fonts-->
  <link href='http://fonts.googleapis.com/css?family=Lato:300,400,700,400italic,700italic' rel='stylesheet'
    type='text/css'>
  <!--CSS-
 <link href="style.css" rel="stylesheet">-->
  <link href="style1.css" rel="stylesheet">
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css" rel="stylesheet" />
  <!--<link href="https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&amp;display=swap" rel="stylesheet" />
  <!-script-->
  <script src="https://cdn.tailwindcss.com"></script>
  
</head>

<body>
  <header class="bg-white shadow-md p-6 flex items-center justify-between flex-wrap">
    <a href="index.html">
      <div class="flex items-center space-x-2 px-4">
        <img class="w-12 h-12" src="Assets/RoundLogo.png" alt="Logo">
        <h2 class="logo text-blue-800 text-2xl md:text-4xl font-bold">iTSIKHWAL</h2>
      </div>
    </a>
  
    <!-- Hamburger Button (for mobile) -->
    <button class="block md:hidden text-blue-800 focus:outline-none" onclick="toggleNav()">
      <svg class="w-6 h-6" fill="none" stroke="currentColor" stroke-width="2"
           viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round">
        <path d="M4 6h16M4 12h16M4 18h16"/>
      </svg>
    </button>
  
    <!-- Nav Menu -->
    <nav id="nav-menu"
         class="w-full md:w-auto md:flex px-16 md:items-center md:space-x-6 space-y-2 md:space-y-0 
                mt-4 md:mt-0 hidden md:block text-black font-bold text-center md:text-left 
                transition-all duration-300 ease-in-out max-h-0 md:max-h-full overflow-hidden ">
      <a href="index.html#Home" class="block md:inline-block" onclick="closeNavOnClick()">Home</a>
      
      <a href="index.html#Projects" class="block md:inline-block" onclick="closeNavOnClick()">Our Projects</a>
      <a href="iVALab.html" class="block md:inline-block" onclick="closeNavOnClick()">AR/VR Lab</a>
      <a href="index.html#About" class="block md:inline-block" onclick="closeNavOnClick()">About</a>
      <a href="index.html#Team" class="block md:inline-block" onclick="closeNavOnClick()">Our Team</a>
      <a href="#Contact" class="block md:inline-block" onclick="closeNavOnClick()">Contact</a>
    </nav>
  </header>
  <section class="relative">
    <div class="container mx-auto px-6"></div>
    <div class="blankBlock text-4xl text-center font-bold py-24 w-full h-175 object-cover" style="background-image: url('Assets/bg.png'); background-size: cover;">
      <div class="absolute inset-0 flex items-center justify-center">
        <span class="text-4x1 font-bold text-white"><br><br><br>iVA Mate</span>
      </div>
    </div>
</section>

<div class="flex flex-wrap justify-center items-center py-10">
    <!--
   

-->
<div class="w-30 md:w-1/2 p-9 h-auto ">
    <img src="Assets/n.jpg" alt="Half Screen Image" class="w-100 h-100 object-cover">
</div>
    <div class="w-full md:w-1/2 h-154 p-10 bg-gray-100 shadow-md">
        <h2 class="text-3xl font-bold mb-4">Research Details</h2>
        <ul class="list-disc list-inside text-lg">
            <li><strong>Project Name:</strong> iVA Mate</li>
            <li><strong>Funding Organization:</strong> Internal Funding</li>
            <li><strong>Funding Instrument:</strong> Self-Investment and via In-App Ads & Premium Features</li>
            <li><strong>Duration:</strong> 6 months (Ongoing)</li>
            <li><strong>Total Budget:</strong> Estimated ₹20,000</li>
            <li><strong>Team Lead:</strong> Tarun Sikhwal (Founder & Scientific Lead)</li>
            <li><strong>Team :</strong> Sanket Shinde, Swapnil Gore, Trupti Pawar, Sanjivani Yawalkar.</li>
            <li><strong>Requried Equipments:</strong> Meta Quest 2</li>
            <li><strong>Focus Area:</strong> Advanced AI, AR/VR and Metaverse</li>
        </ul>
    </div>
 
    <iframe class="mt-20" width='800' height='450' src="https://www.youtube.com/embed/JjY7U6FwtKM?&theme=dark&autohide=2"frameborder="0"></iframe><div style='font-size: 0.8em'><a href='http://codegena.com/generator/Youtube-Embed-Code-Generator.html'></a></div>
    
    
</div>



<div class="flex justify-center items-center py-12 mt-40">
    <div class="w-full md:w-4/5 lg:w-1/2 p-4 bg-white ">
        <h2 class="text-3xl font-bold mb-4 text-center">Abstract</h2>
        <p class="text-lg text-justify">The project aimed to connect each user represented by avatar, accompanied by a personal AI-powered virtual assistant. The assistant leveraged artificial intelligence (AI), machine learning, and Metaverse Technology to enhance the user experience by providing real-time support and personalized guidance from Virtual Assistant within the metaverse. Users were able to navigate the virtual world, all facilitated by their virtual assistants. A key feature of this innovation was the multiplayer interaction functionality, which enabled users to interact with each other’s avatars and communicate through audio in real time in the present of each user’s AI Assistant. This interaction fostered knowledge sharing and community engagement, while the AI assistants provided contextual information and support during these exchanges. By integrating AI-driven assistance with seamless multiplayer communication, the project aimed to create an engaging and interactive metaverse environment, enhancing user satisfaction, collaboration, and learning outcomes.</p>
    </div>
</div>
 
<div class="flex flex-wrap justify-center items-center py-12 px-4">
  <!-- Heading -->
  <div class="w-full text-center mb-6">
    <h2 class="text-2xl md:text-3xl font-bold text-blue-800">
      Achievements in Innovation and Research
    </h2>
  </div>

  <!-- Images Section -->
  <div class="w-full flex flex-col lg:flex-row items-center justify-center gap-4">
    <img src="Assets/Paper.jpg" alt="Accomplishment 1" class="w-full lg:w-1/2 h-auto rounded-lg shadow-lg">
    <img src="Assets/Paper.png" alt="Accomplishment 2" class="w-full lg:w-1/2 h-auto rounded-lg shadow-lg">
  </div>
</div>



<div class="flex flex-wrap justify-center items-center py-12">
    <div class="w-full  p-4">
        <h2 class="text-3xl font-bold mb-4">Result & Snapshots</h2>
         </div>
</div>
<section class="gallery relative">
    <div class="container mx-auto px-6">
        <div class="grid grid-cols-1 sm:grid-cols-2 md:grid-cols-3 gap-4">
            <div class="relative">
                <img src="Assets/p1 (1).jpg" alt="Gallery Image 1" class="w-full h-full object-cover">
            </div>
            <div class="relative">
                <img src="Assets/p2.png" alt="Gallery Image 2" class="w-full h-full object-cover">
            </div>
            <div class="relative">
                <img src="Assets/p1 (2).png" alt="Gallery Image 3" class="w-full h-full object-cover">
            </div>
            <div class="relative">
                <img src="Assets/p1 (3).png" alt="Gallery Image 4" class="w-full h-full object-cover">
            </div>
            <div class="relative">
                <img src="Assets/p1 (4).png" alt="Gallery Image 5" class="w-full h-full object-cover">
            </div>
            <div class="relative">
                <img src="Assets/p1 (1).png" alt="Gallery Image 6" class="w-full h-full object-cover">
            </div>
        </div>
    </div>
</section>
<script>
    document.querySelectorAll('.gallery img').forEach(img => {
        img.addEventListener('click', () => {
            const viewer = document.createElement('div');
            viewer.style.position = 'fixed';
            viewer.style.top = '0';
            viewer.style.left = '0';
            viewer.style.width = '100%';
            viewer.style.height = '100%';
            viewer.style.backgroundColor = 'rgba(0, 0, 0, 0.8)';
            viewer.style.display = 'flex';
            viewer.style.alignItems = 'center';
            viewer.style.justifyContent = 'center';
            viewer.style.zIndex = '1000';
            viewer.innerHTML = `<img src="${img.src}" style="max-width: 90%; max-height: 90%;">`;
            viewer.addEventListener('click', () => {
                document.body.removeChild(viewer);
            });
            document.body.appendChild(viewer);
        });
    });
</script>

<div class="flex  m-20">
    <div class="w-full p-4 bg-white p-0 text-lg text-justify">
        <h2 class="text-3xl font-bold mb-4 text-center">Description</h2>
        <p class="text-lg text-justify">This section provides a detailed description of the iVA Mate project, highlighting its objectives, methodologies, and expected outcomes. The project leverages cutting-edge technologies such as AI, AR/VR, and Metaverse to create an immersive and interactive virtual environment. Users are represented by avatars and assisted by AI-powered virtual assistants, enhancing their experience through real-time support and personalized guidance. The multiplayer interaction functionality allows users to communicate and collaborate within the metaverse, fostering a sense of community and knowledge sharing.</p>
    
        <h4 class="text-1xl font-bold mb-4 pt-5">FIELD OF THE INVENTION</h4>
        <p class="text-lg text-justify">
            The field of this invention lies in Virtual Reality (VR), Artificial Intelligence (AI), and Metaverse Technology. Specifically, it involves creating an immersive virtual experience where each user is represented by a unique avatar accompanied with a personal virtual assistant powered by AI. The invention integrates AI-driven virtual assistance with multiplayer interaction, enhancing user engagement, education, resource management, and social collaboration in a virtual environment. User can interact with there 3D Virtual Assistant by voice input to communication with there AI assistant in real time. This invention aims to transform the metaverse experience by combining advanced AI capabilities with real-time user interaction, making it more dynamic, interactive, and personalized.
            </p>


            <h4 class="text-1xl font-bold mb-4 pt-5">BACKGROUND OF THE INVENTION</h4>
As the concept of the metaverse gains traction, there is a growing need for innovative solutions that enhance user interaction and engagement within these virtual environments. Current VR platforms often lack the depth of personalized assistance and dynamic interaction that users need to fully immerse themselves and achieve specific objectives, such as learning, collaboration, or entertainment. Users struggle with navigating complex virtual worlds, managing resources, or finding relevant information, which can detract from their overall experience and limit the potential of the metaverse as a tool for education, collaboration, and socialization. Traditional virtual assistants lack the contextual understanding and adaptability required to function effectively in a shared VR environment. Furthermore, while some multiplayer VR environments offer real-time communication, they often do not integrate AI-powered assistants that can enhance interactions by providing contextual knowledge, guidance, and support. This invention addresses these limitations by combining a personal AI assistant for each user with real-time multiplayer interactions, offering a more intuitive, engaging, and effective experience.

<h4 class="text-1xl font-bold mb-4 pt-5">SUMMARY OF THE INVENTION</h4>
The invention was developed as a comprehensive virtual reality (VR) platform designed to integrate AI-powered virtual assistants within a multiplayer environment, where each user is represented by a unique avatar and there AI Assistant as 3D Model which follow the User in the virtual world. The invention aimed to address the limitations of existing VR systems by enhancing user interaction and engagement through personalized, intelligent assistance and seamless social connectivity.
Each virtual assistant was engineered to leverage advanced artificial intelligence (AI), machine learning, and natural language processing (NLP) technologies to provide personalized guidance, manage resources, and offer real-time support to users. These AI assistants dynamically adapted to each user’s individual preferences, behaviors, and needs, offering tailored assistance that enriched the overall experience in the metaverse. The assistants were capable of understanding and responding to natural language queries, helping users navigate the virtual environment, and providing contextual information or instructions as needed.
The invention also enabled multiple users to interact with one another using their avatars and voice communication, creating a vibrant, socially interactive virtual space with there assistants. The platform fostered collaboration, knowledge sharing, and social engagement by allowing users to communicate in real-time and work together on various tasks or activities. The AI assistants supported these interactions by providing relevant information, answering queries, and assisting users in accomplishing objectives within the virtual environment. For example, an AI assistant help the users to find specific locations, offer learning resources, or suggest collaborative activities based on the group’s dynamics.
By integrating AI-driven virtual assistants with real-time multiplayer interactions, the invention created a dynamic and interactive VR experience. This approach not only enhanced the overall immersion but also increased user satisfaction and engagement as they can get help form AI Assistant for solving any quires. The platform was designed to offer personalized learning experiences, facilitate efficient knowledge sharing, and provide continuous support, ultimately leading to improved learning outcomes and a more engaging and enjoyable metaverse experience.



<h4 class="text-1xl font-bold mb-4 pt-5">DETAILED DESCRIPTION OF THE INVENTION</h4>
This invention is centered on creating a Virtual Reality (VR) platform where multiple users can interact in a shared virtual environment, each represented by an avatar with an accompanying AI-powered virtual assistant.

<h4 class="text-1xl font-bold mb-4 pt-5">1.	Design and Development of 3D Virtual Assistant</h4>
3D Models: Pet like Robots, Cartoon Characters 
The 3D models for the AI-powered virtual assistants in this invention are designed to be engaging and approachable, resembling pet-like robots and cartoon characters. These assistants are visually appealing and easy to interact with, featuring expressive movements and gestures to enhance their personalities. Pet-like robots may have sleek, futuristic designs with glowing features and soft, rounded shapes, while cartoon characters are vibrant, colorful, and stylized with exaggerated proportions, making them both fun and relatable for users of all ages. These designs aim to create a friendly, approachable virtual companion, increasing user engagement and immersion in the metaverse.

Animations: Animations like talking, listening, and running bring 3D characters to life by simulating natural movements. Talking animations involve lip-syncing to dialogue, along with facial expressions and gestures to convey emotions. Listening animations use subtle body language, eye movements, and facial reactions to show attention. Running animations focus on full-body motion, including coordinated leg and arm movements, realistic foot placement, and secondary motion like hair or clothing bounce. These animations are created through keyframe animation, for enhancing realism and immersion in virtual world.

Follow the User: In the virtual world, Assistant continue to follow the user involves the 3D character moving alongside or behind the user, maintaining proximity and staying in sync with their actions. The model uses tracking algorithms to match the user’s movements, ensuring it remains within a specified distance or visual field. 
A Nav Mesh Agent is an AI-driven entity in a 3D environment that navigates using a Navigation Mesh (NavMesh), which represents walkable areas. The NavMesh helps the AI calculate optimal paths while avoiding obstacles and adapting to terrain changes. By employing algorithms like NavMesh, assistant can move smoothly and intelligently.

<h4 class="text-1xl font-bold mb-4 pt-5">2.	Interaction Between User and Assistant</h4>
Interaction between a user and an assistant involves a dynamic exchange where the assistant responds to user queries, provides information, and performs tasks based on the user's needs. This interaction can occur through various mediums, such as text, voice.
Speech Recognition: Speech recognition is a technology that converts spoken language into written text. It utilizes advanced algorithms and machine learning techniques to analyze and interpret audio signals, enabling communication and user interaction between user and there AI Assistant.

Generative AI Model API, Prompt Engineering, History Saving for Context Information 
By leveraging the power of machine learning, Generative AI model produces human-like responses and creative outputs, making them invaluable in interaction with the user.
Prompt engineering plays a crucial role in maximizing the effectiveness of generative AI by carefully crafting prompts that guide the AI to produce relevant and high-quality responses. This involves understanding the nuances of the AI's behavior and iteratively refining prompts for optimal results. Additionally, history saving for context information allows the AI to retain and reference previous interactions, enabling more coherent and personalized conversations. Together, these practices significantly enhance the user experience, allowing for deeper engagement and more meaningful interactions with generative AI applications.

Text To Speech: Cartoon Voice
Text-to-Speech (TTS) technology converts written text into spoken words with a cartoon voice that features playful and exaggerated qualities typical of animated characters. Key features include voice modulation for pitch and tone, characterization to reflect different personalities, and emotional inflections to enhance engagement.






<h4 class="text-1xl font-bold mb-4 pt-5">3.	Multiplayer Interaction </h4>
Multiplayer interaction refers to the way multiple users or players interact with each other in a shared digital environment, virtual world, or online platform. multiplayer interaction in a virtual environment refers to how participants collaborate, communicate, and share content

Avatars are digital representations of individuals users in virtual environments, allowing users to express themselves creatively and interactively as Virtual Avatars. They can range from realistic 3D models to stylized or cartoon-like characters, reflecting the user's personality, preferences, or mood. Avatars serve as a means of communication and engagement in virtual environment, enabling users to connect and interact with other users in a personalized way while navigating digital spaces.
Lobby: 
A lobby refers to a designated space within a virtual environment where users can gather, socialize, and interact before entering a specific activity or event, such as a game or meeting. It serves as a waiting area that facilitates communication and community-building among participants. Lobbies has the feature like customizable avatars, chat options, and various interactive elements, allowing users to prepare for their next engagement, strategize with teammates, or simply connect with friends and other players.

Voice Chat:
Voice chat is a feature that allows users to communicate with each other through audio in real time, enhancing interaction within virtual environments or gaming platforms. It enables players or participants to discuss strategies, coordinate actions, or socialize without relying solely on text-based communication. Voice chat can be integrated into various platforms, providing users with a more immersive and engaging experience by allowing for natural conversation and immediate feedback, making it particularly valuable in fast-paced gaming scenarios or collaborative online activities.

Multiple Assistants in world with Avatars 
In the virtual world, each user is represented by an avatar accompanied by a personalized AI-powered assistant. These assistants, designed as engaging 3D models like pet-like robots or cartoon characters, follow the user’s movement. The AI Navigation calculate optimal paths while avoiding obstacles and adapting to terrain changes. Users can see and interact with each other’s assistant’s, if permitted. The assistants are capable of speaking, running, and responding to voice commands, using advanced animations and speech recognition to create a dynamic and interactive experience. User are able to view the movement of all the assistants and their activities. Multiplayer interaction is facilitated, allowing users to collaborate and engage socially while their assistants provide contextual support and guidance in real-time.

<h2 class="text-3xl font-bold mb-4 text-center p-9">Technical Implementation of Virtual Environment</h2>
<h4 class="text-1xl font-bold mb-4 pt-5">1.	Unity Game Engine</h4>
In the project we unity 3d game engine for the project development in the virtual environment will be built using the Unity Game Engine, a powerful and versatile platform for creating immersive 3D virtual assistant for the metaverse and VR experiences. Unity offers a wide range of tools for rendering realistic environments by using this we developed the environments, managing complex interactions is possible in unity we use the unity to connect the assistant with the AI model also assigned different animation to the 3D model, and handling multiplayer capabilities which means we use unity for the multiplier interaction, which makes it ideal for implementing this invention.

<h4 class="text-1xl font-bold mb-4 pt-5">2.	Unity Cloud</h4>
Cloud-based services are offered by Unity Cloud to facilitate testing, multiplayer features, and continuous integration. In this project, Unity Cloud will be used for: 
Real-Time Multiplayer Synchronization: The networking technology of Unity Cloud will enable smooth synchronization between numerous users in a shared virtual reality environment. This will guarantee that there is no lag or desynchronization during interactions between avatars and AI helpers in real-time. In our project, we deploy multiplayer interaction through the usage of Unity Cloud, which allows several users to connect with one other via voice and avatar. 


<h4 class="text-1xl font-bold mb-4 pt-5">3.	VR Headset: 6DOF</h4>
The virtual world will work with 6DOF VR headsets, which provide an entirely immersive experience by tracking the user's head and hands in both position and rotation. Increased User Mobility: By allowing users to walk, squat, lean, and spin, the virtual environment may be navigated more naturally. This is particularly crucial to make sure AI helpers correctly track users and adapt to their motions in real time. The incorporation of voice chat functionality with 6DOF guarantees a more organic communication experience among users. With spatial audio adding to the realism, users may converse with other avatars or their AI assistants face-to-face as if they were in the same physical location.

  
    </div>
</div>

<footer class="bg-white py-8">
  <section id="Contact">
  <div class="container mx-auto px-4">
    <h2 class="text-3xl font-bold text-center mb-8">Contact</h2><hr>
    <div class="flex flex-col md:flex-row justify-between items-center text-center md:text-left">
      <div class="mb-6 md:mb-0 md:w-1/3">
        <div class="flex items-center justify-center md:justify-start">
          <i class="fas fa-map-marker-alt text-purple-600 text-2xl mr-2"></i>
          <div>
              <h3 class="text-lg font-bold text-black-900 mx-5">Location</h3>
              <p class="text-gray-600 mx-5">G H RAISONI COLLEGE OF ENGINEERING <br>AND MANAGEMENT,PUNE</p>
              <p class="text-gray-600 mx-5"> New Gat No. 1200 , Domkhel Road ,<br>
                  Wagholi , Pune 412207, Maharashtra State, India </p>
            </a>
          </div>
        </div>
      </div>
      <div class="mb-6 md:mb-0 md:w-1/3">
        <div class="flex items-center justify-center md:justify-start">
          <i class="fas fa-phone-alt text-purple-600 text-2xl mr-2"></i>
          <div>
            <h3 class="text-lg font-bold text-black-900 mx-5">Call Us On</h3>
            <p class="text-gray-600 mx-5">+91 77098 46067</p>
          </div>
        </div>
      </div>
      <div class="md:w-1/3">
        <div class="flex items-center justify-center md:justify-start">
          <i class="fas fa-envelope text-purple-600 text-2xl mr-2"></i>
          <div>
            <h3 class="text-lg font-bold text-black-900 mx-5">Email Us</h3>
            <p class="text-gray-600 mx-5">itsikhwal@gmail.com</p>
          </div>
        </div>
      </div>
    </div>
    <div class="border-t border-gray-300 mt-8 pt-4 text-center">
      <p class="text-gray-600">Copyright © 2024 <span class="font-bold text-blue-900">iTSikhwal Pvt. Ltd</span>. All rights
        reserved.</p>
      <div class="flex justify-center mt-4">
        <a href="https://www.facebook.com/iTSikhwal" class="text-blue-600 mx-5"><i class="fab fa-facebook-f"></i></a>
        <a href="https://x.com/iTSikhwal" class="text-black-600 mx-2"><i class="fab fa-twitter"></i></a>
        <a href="https://www.linkedin.com/company/iTSikhwal/" class="text-blue-600 mx-5"><i class="fab fa-linkedin-in"></i></a>
        <a href="https://www.instagram.com/iTSikhwal/" class="text-pink-600 mx-2"><i class="fab fa-instagram"></i></a>
      </div>
    </div>
  </div>
</section>
</footer>
<script src="script.js"></script>
</body>
</html>